import numpy as npimport matplotlib.pyplot as pltimport pandas as pdfrom sklearn.ensemble import GradientBoostingRegressor# Step 1: Generate datasetnp.random.seed(42)X = np.random.rand(100, 1) - 0.5 # Random X values in [-0.5, 0.5]y = 3 * X[:, 0]**2 + 0.05 * np.random.randn(100) # Parabolic relation with noise# Convert to DataFrame (optional, for easy viewing)df = pd.DataFrame({'X': X[:, 0], 'y': y})# Step 2: Create Gradient Boosting Regressormodel = GradientBoostingRegressor( n_estimators=200, # number of boosting stages learning_rate=0.1, # step size shrinkage max_depth=3, # tree depth (controls model complexity) random_state=42
)# Step 3: Train modelmodel.fit(X, y)# Step 4: Predict on a smooth range of X for curve plottingX_test = np.linspace(-0.5, 0.5, 200).reshape(-1, 1)y_pred = model.predict(X_test)# Step 5: Plot resultsplt.figure(figsize=(8,6))plt.scatter(X, y, color='blue', label='Training Data')plt.plot(X_test, y_pred, color='red', linewidth=2, label='Gradient Boosting Fit')plt.title("Gradient Boosting Regression Example")plt.xlabel("X")plt.ylabel("y")plt.legend()plt.show()

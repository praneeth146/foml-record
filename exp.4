mport numpy as np# -----------------------------# Step 1: Define input and output (OR logic)# -----------------------------# Inputs: 2 binary featuresx = np.array([
[0, 0], [0, 1], [1, 0], [1, 1]])# Expected output for OR gatey = np.array([[0], [1], [1], [1]])# -----------------------------# Step 2: Initialize weights and bias# -----------------------------np.random.seed(42)weights = np.random.rand(2, 1) # 2 inputs → 1 outputbias = np.random.rand(1)learning_rate = 0.1# -----------------------------# Step 3: Define activation (step) function# -----------------------------def activation(z): return np.where(z >= 0, 1, 0)# -----------------------------# Step 4: Train the Perceptron# -----------------------------epochs = 10for epoch in range(epochs): for i in range(len(x)): # Weighted sum z = np.dot(x[i], weights) + bias # Activation output y_pred = activation(z) # Compute error error = y[i] - y_pred # Update weights and bias weights += learning_rate * error * x[i].reshape(2, 1) bias += learning_rate * error print(f"Epoch {epoch+1}: Weights = {weights.T}, Bias = {bias}")# -----------------------------# Step 5: Test the trained perceptron# -----------------------------print("\n=== Testing Trained Perceptron ===")for i in range(len(x)): z = np.dot(x[i], weights) + bias y_pred = activation(z) print(f"Input: {x[i]} → Output: {int(y_pred)}")
